{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Продвинутое машинное обучение: ДЗ 3\n",
    "\n",
    "В этом небольшом домашнем задании мы попробуем улучшить метод Шерлока Холмса. Как известно, в рассказе The Adventure of the Dancing Men великий сыщик расшифровал загадочные письмена.\n",
    "\n",
    "Пользовался он для этого так называемым частотным методом: смотрел, какие буквы чаще встречаются в зашифрованных текстах, и пытался подставить буквы в соответствии с частотной таблицей: E — самая частая и так далее.\n",
    "\n",
    "В этом задании мы будем разрабатывать более современный и продвинутый вариант такого частотного метода.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "from copy import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Содержание\n",
    "\n",
    "0. [Загрузка и обработка данных](#data_load)\n",
    "1. [Частотное декодирование на основе униграмм](#unigramm)\n",
    "2. [Частотное декодирование на основе биграмм](#bigramm)\n",
    "3. [Декодирование с помощью MCMC алгоритма](#mcmc)\n",
    "4. [Расшифровка тестового текста](#decoding)\n",
    "5. [Сравнение моделей](#n_gramm_mcmc)\n",
    "6. [Применение модели](#model_usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и обработка данных <a name = \"data_load\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data'\n",
    "\n",
    "with open(os.path.join(DATA_PATH, 'AnnaKarenina.txt'), 'r') as f1, \\\n",
    "     open(os.path.join(DATA_PATH, 'WarAndPeace.txt'), 'r') as f2:\n",
    "    anna_karenina = f1.read().lower()\n",
    "    war_and_peace = f2.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = anna_karenina + war_and_peace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Частотное декодирование на основе униграмм <a name = \"unigramm\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "\n",
    "* подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "* возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе совсем вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "* расшифруйте их таким частотным методом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим два алфавита: английский и русский"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENG_ALPHABET = string.ascii_lowercase + ' '\n",
    "RU_ALPHABET = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrequencyDecoder: \n",
    "    \n",
    "    def __init__(self, language: str = \"ru\", n_gram_len: int = 1):\n",
    "        self.language = language\n",
    "        self.n_gram_len = n_gram_len\n",
    "        if (self.language == \"ru\"):\n",
    "            self.__alphabet = RU_ALPHABET\n",
    "        elif (self.language == \"eng\"):\n",
    "            self.__alphabet = ENG_ALPHABET\n",
    "        else:\n",
    "            raise ValueError(\"Wrong language\")\n",
    "            \n",
    "    def train(self, text: str):\n",
    "        text = self.preprocess(text)\n",
    "        n_grams = self.__get_ngrams(text)\n",
    "        self.__frequency_dict = self.__get_frequency_dict(n_grams)\n",
    "        \n",
    "    def decode(self, text: str) -> str:\n",
    "        text += ' ' * (len(text) % self.n_gram_len)\n",
    "        n_grams = self.__get_ngrams(text)\n",
    "        decoded_frequency_dict = self.__get_frequency_dict(n_grams)\n",
    "        interim_size = min(len(decoded_frequency_dict), len(self.__frequency_dict))\n",
    "        interim = {}\n",
    "        for i in range(interim_size):\n",
    "            interim[[*decoded_frequency_dict][i]] = [*self.__frequency_dict][i]\n",
    "        return ''.join([interim[ng] for ng in n_grams])[:len(text)]\n",
    "        \n",
    "        \n",
    "    def preprocess(self, text: str):\n",
    "        return ''.join([c for c in text.lower() if c in self.__alphabet])\n",
    "    \n",
    "    def __get_ngrams(self, text: str) -> list:\n",
    "        return [text[i:i+self.n_gram_len] for i in range(len(text) - self.n_gram_len + 1)]\n",
    "    \n",
    "    def __get_frequency_dict(self, n_grams: list) -> dict:\n",
    "        return {k: v for k, v in sorted(Counter(n_grams).items(), key=lambda item: -item[1])}\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplaceEncoder:\n",
    "    \n",
    "    def __init__(self, language: str = \"ru\"):\n",
    "        self.language = language\n",
    "        if (self.language == \"ru\"):\n",
    "            self.__alphabet = RU_ALPHABET\n",
    "        elif (self.language == \"eng\"):\n",
    "            self.__alphabet = ENG_ALPHABET\n",
    "        else:\n",
    "            raise ValueError(\"Wrong language\")\n",
    "            \n",
    "        self.__permutation = ''.join(random.sample(self.__alphabet,len(self.__alphabet)))\n",
    "        self.__translator = str.maketrans(self.__alphabet, self.__permutation)\n",
    "            \n",
    "            \n",
    "    def encode(self, text: str) -> str:\n",
    "        return self.__translate(self.__preprocess(text))\n",
    "    \n",
    "    \n",
    "    def __preprocess(self, text: str) -> str:\n",
    "        return ''.join([c for c in text.lower() if c in self.__alphabet])\n",
    "    \n",
    "    \n",
    "    def __translate(self, text: str) -> str:\n",
    "        return text.translate(self.__translator)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитаем частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_decoder = FrequencyDecoder('ru')\n",
    "unigram_decoder.train(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем тестовый тексты (нужно взять по меньшей мере 2-3 предложения, иначе совсем вряд ли сработает), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"\"\"\n",
    "Проснувшись, мы пересмотрели все добро, награбленное шайкой на разбитом пароходе; \\\n",
    "там оказались и сапоги, и одеяла, и платья, и всякие другие вещи, а еще много книг, \\\n",
    "подзорная труба и три ящика сигар. Такими богачами мы с Джимом еще никогда в жизни не были. \\\n",
    "Сигары оказались первый сорт. До вечера мы валялись в лесу и разговаривали; я читал книжки; \\\n",
    "и вообще мы недурно провели время. Я рассказал Джиму обо всем, что произошло на пароходе и на пароме, \\\n",
    "и сообщил ему кстати, что это и называется приключением; а он ответил, \\\n",
    "что не желает больше никаких приключений. Джим рассказал, что в ту минуту, \\\n",
    "когда я залез в рубку, а он прокрался обратно к плоту и увидел, что плота больше нет, \\\n",
    "он чуть не умер со страха: так и решил, что ему теперь крышка, чем бы дело ни кончилось, \\\n",
    "потому что если его не спасут, так он утонет; а если кто нибудь его спасет, так отвезет домой, \\\n",
    "чтобы получить за него награду, а там мисс Уотсон, наверно, продаст его на Юг. \\\n",
    "Что ж, он был прав; он почти всегда бывал прав, голова у него работала здорово, - для негра, конечно.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст в изначальном виде:\n",
      "\n",
      "\n",
      "Проснувшись, мы пересмотрели все добро, награбленное шайкой на разбитом пароходе; там оказались и сапоги, и одеяла, и платья, и всякие другие вещи, а еще много книг, подзорная труба и три ящика сигар. Такими богачами мы с Джимом еще никогда в жизни не были. Сигары оказались первый сорт. До вечера мы валялись в лесу и разговаривали; я читал книжки; и вообще мы недурно провели время. Я рассказал Джиму обо всем, что произошло на пароходе и на пароме, и сообщил ему кстати, что это и называется приключением; а он ответил, что не желает больше никаких приключений. Джим рассказал, что в ту минуту, когда я залез в рубку, а он прокрался обратно к плоту и увидел, что плота больше нет, он чуть не умер со страха: так и решил, что ему теперь крышка, чем бы дело ни кончилось, потому что если его не спасут, так он утонет; а если кто нибудь его спасет, так отвезет домой, чтобы получить за него награду, а там мисс Уотсон, наверно, продаст его на Юг. Что ж, он был прав; он почти всегда бывал прав, голова у него работала здорово, - для негра, конечно.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Текст в изначальном виде:\\n\")\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зашифруем их посредством случайной перестановки символов;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Зашифрованный случайными перестановками текст:\n",
      "\n",
      "йы цштуирцчавбайъыъцв лыъмрауцъаь ёы ашеэыеёмъшш ъаиеос оашеаыепёрл вайеы н ьъалева сепемрцчарацей эрара ьъзмеараймелчзарауцзсръаьытэръауъжраеаъжъавш э асшрэай ьп ышезалытёеаралыразжрсеацрэеыалесрвраё эефевравбацаьюрв ваъжъашрс эьеауаюрпшрашъаёбмрацрэеыба сепемрцчайъыубоац ылаь ауъфъыеавбауемзмрцчауамъцтараыепэ уеыруемразафрлемасшрюсрарау  ёжъавбашъьтыш айы уъмрауыъвзазаыеццсепемаьюрвта ё ауцъвафл айы рп им ашеайеы н ьъарашеайеы въарац  ёжрмаъвтасцлелрафл акл арашепбуеълцзайырсмдфъшръваеа ша луълрмафл ашъаюъмеълаё мчиъашрсесрнайырсмдфъшроаьюрваыеццсепемафл ауалтаврштлтас эьеазапемъпауаытёстаеа шайы сыемцза ёыелш асайм лтаратурьъмафл айм леаё мчиъашъла шафтлчашъатвъыац ацлыенеалесараыъирмафл аъвталъйъычасыбисеафъваёбаьъм ашрас шфрм цчай л втафл аъцмраъэ ашъацйецтлалеса шатл шълаеаъцмрасл ашрётьчаъэ ацйецълалеса луъпълаь в оафл ёбай мтфрлчапеашъэ ашеэыеьтаеалеваврццат лц шашеуъыш айы ьецлаъэ ашеадэафл аюа шаёбмайыеуа шай флрауцъэьеаёбуемайыеуаэ м уеаташъэ аыеё лемеапь ы у ааьмзашъэыеас шъфш \n"
     ]
    }
   ],
   "source": [
    "replace_encoder = ReplaceEncoder('ru')\n",
    "encoded_test_text = replace_encoder.encode(test_text)\n",
    "print(\"Зашифрованный случайными перестановками текст:\\n\")\n",
    "print(encoded_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расшифруем их частотным методом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расшифрованный текст с помощью частотной униграммы:\n",
      "\n",
      "мсовтукжнвч дб масавдоисалн ква погсо теясеглаттоа жехрох те сеыгниод месоюопа иед ореыелнвч н вемоян н опазле н млеичз н квзрна псуяна кашн е аша дтояо ртня мопыостез исуге н исн зшнре вняес иерндн гояеьедн дб в пйндод аша тнрояпе к йнытн та гблн вняесб ореыелнвч маскбх воси по каьасе дб келзлнвч к лаву н сеыяокеснкелн з ьниел ртнйрн н коогша дб тапусто мсокалн ксадз з севвреыел пйнду ого квад ьио мсоныожло те месоюопа н те месода н воогшнл аду рвиеин ьио цио н теыбкеаивз мснрлэьатнад е от оикаинл ьио та йалеаи голчжа тнрерню мснрлэьатнх пйнд севвреыел ьио к иу днтуиу рояпе з ыелаы к сугру е от мсорселвз огсеито р млоиу н укнпал ьио млоие голчжа таи от ьуич та удас во висеюе иер н сажнл ьио аду иамасч рсбжре ьад гб пало тн ротьнловч моиоду ьио авлн аяо та вмевуи иер от уиотаи е авлн рио тнгупч аяо вмеваи иер оикаыаи подох ьиогб молуьнич ые таяо теясепу е иед днвв уоивот текасто мсопеви аяо те эя ьио й от гбл мсек от моьин кваяпе гбкел мсек яолоке у таяо сегоиеле ыпосоко  плз таясе ротаьто\n"
     ]
    }
   ],
   "source": [
    "decoded_test_text = unigram_decoder.decode(encoded_test_text)\n",
    "print(\"Расшифрованный текст с помощью частотной униграммы:\\n\")\n",
    "print(decoded_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введем метрику качества декодирования, как долю верно расшифрованных символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(orig_text, decoded_text):\n",
    "    return sum(np.array(list(orig_text)) == np.array(list(decoded_text))) / len(orig_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Частотный алгоритм на униграмммах\n",
      "Доля верно расшифрованных символовов 0.3396414342629482\n"
     ]
    }
   ],
   "source": [
    "print(\"Частотный алгоритм на униграмммах\")\n",
    "print(f\"Доля верно расшифрованных символовов {accuracy(unigram_decoder.preprocess(test_text), decoded_test_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Частотное декодирование на основе биграмм <a name = \"bigramm\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате не получилась хорошая расшифровка. Так что давайте сделаем следующий логический шаг:\n",
    "* подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "* проведите тестирование аналогично п.1, но при помощи биграмм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_decoder = FrequencyDecoder('ru', 2)\n",
    "bigram_decoder.train(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расшифрованный текст с помощью частотной биграммы:\n",
      "\n",
      "коневыкуылар хейзан онм одро соболвеаксивсй ы ветакао товида новазтьеднеи е  тсою  виеих лмоятелжа нжиийтувнскоечте  та  б вотрыыйче птеен сомернеис ж еле нал койен оаву оторнаказан оня о нощечианк дио я о  о елеепше за я о  с а зсянылсния о товисьош ус  новмнннымдис  нтов мемио ога л мех  нм улелк  ди   холаимев сан еебча эки тлуниалы ннпеька я о алы быо  рньмириу а ноадимиверняал кил ужеемо прдек ивутпаойемо м одронобоовэтсежевстеенл мех  не ларискк му га то ммасе яьнлао е ст нпрт бекао ноадимиверееро оаву оторнаказан он соболажезопчтноин эбрвоовази тов знесол ва м одротолинаожшеказан онто мус лаксвь я о  б вотум дтилиербывшлинакао  рни итрче кнара  холакнгд уо я о тоиздутьлях  нм одрое стувияугкиели  сконетив такао тоз вевашани рни б ваттвичу оторнараовэтсежеить  отьдеи товидаваен иго пи  сконетн ячабуывреи е  та  сомернеис ж еле ня о е  та  сомернетеса ня о ноиндутьлямидорал ваить   лыая ксяамо  иго пи жнд  пи я о е  тотаесплиудосдрсьни скобыришиикокесмолас ваенога  опо ч ой идв осамдо\n"
     ]
    }
   ],
   "source": [
    "decoded_test_text_2 = bigram_decoder.decode(encoded_test_text)\n",
    "print(\"Расшифрованный текст с помощью частотной биграммы:\\n\")\n",
    "print(decoded_test_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Частотный алгоритм на биграммах\n",
      "Доля верно расшифрованных символовов 0.06772908366533864\n"
     ]
    }
   ],
   "source": [
    "print(\"Частотный алгоритм на биграммах\")\n",
    "print(f\"Доля верно расшифрованных символовов {accuracy(bigram_decoder.preprocess(test_text), decoded_test_text_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стало еще хуже, потому что количество биграмм намного больше, чем количество букв, попасть сложнее. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Декодирование с помощью MCMC алгоритма <a name = \"mcmc\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная часть задания — в том, как можно улучшить биграммы.\n",
    "\n",
    "* Предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "* Реализуйте и протестируйте его, убедитесь, что результаты улучшились.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм следующий. Повторяем n_iter раз:\n",
    "\n",
    "* Меняем местами две случайные буквы в \"перестановке шифрования\"\n",
    "* Оцениваем вероятность получить деловдирванный с помощью этой перестановки текст. У нас есть наша \"языковая модель\", а точнее частотный словарь n-грамм, построенный на тренировочных текстах. Из него мы знаем вероятности встретить n-граммы. Таким образом, мы можем посчитать likelihood декодированного текста как произведение вероятностей для всех n-грамм в нем.\n",
    "* Принимаем или отклоняем перестановку шифрования (если новый likelihood больше, то принимаем, если меньше, то принимаем с вероятностью new_llh / old_llh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCMCDecoder:\n",
    "    \n",
    "    def __init__(self, n_gram_len, language = \"ru\", n_iter=20000, verbose=5000):\n",
    "        \n",
    "        self.language = language\n",
    "        self.n_gram_len = n_gram_len\n",
    "        if (self.language == \"ru\"):\n",
    "            self.__alphabet = RU_ALPHABET\n",
    "        elif (self.language == \"eng\"):\n",
    "            self.__alphabet = ENG_ALPHABET\n",
    "        else:\n",
    "            raise ValueError(\"Wrong language\")\n",
    "        \n",
    "        self.n_iter = n_iter\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        \n",
    "    def loglikelihood(self, text):\n",
    "        text += ' ' * (len(text) % self.n_gram_len)\n",
    "        n_grams = self.__get_ngrams(text)\n",
    "        frequency_dict = self.__get_frequency_dict(n_grams)\n",
    "        return np.sum([count * np.log(self.__frequency_dict.get(ngram, 1 / len(self.__alphabet) ** 2)) \n",
    "                       for ngram, count in frequency_dict.items()])\n",
    "    \n",
    "    \n",
    "    def __get_ngrams(self, text: str) -> list:\n",
    "        return [text[i:i+self.n_gram_len] for i in range(len(text) - self.n_gram_len + 1)]\n",
    "    \n",
    "     \n",
    "    def __get_frequency_dict(self, n_grams: list) -> dict:\n",
    "        return {k: v for k, v in sorted(Counter(n_grams).items(), key=lambda item: -item[1])}\n",
    "             \n",
    "    def __mutate(self, text):\n",
    "        tl = list(text)\n",
    "        letters = np.random.choice(list(self.__alphabet), 2, replace=False)\n",
    "        for i in range(len(text)):\n",
    "            if tl[i] == letters[0]:\n",
    "                tl[i] = letters[1]\n",
    "            elif tl[i] == letters[1]:\n",
    "                tl[i] = letters[0]\n",
    "        return ''.join(tl)\n",
    "    \n",
    "    def __accept(self, cur_llh, new_llh):\n",
    "        if new_llh > cur_llh:\n",
    "            return True\n",
    "        return np.random.rand() < np.exp(new_llh - cur_llh)\n",
    "    \n",
    "    def preprocess(self, text: str):\n",
    "        return ''.join([c for c in text.lower() if c in self.__alphabet])\n",
    "    \n",
    "    def train(self, text):\n",
    "        text = self.preprocess(text)\n",
    "        n_grams = self.__get_ngrams(text)\n",
    "        self.__frequency_dict = self.__get_frequency_dict(n_grams)\n",
    "        \n",
    "        \n",
    "    def decode(self, text, n_iter=20000, is_verbose = True):\n",
    "        best_decoded_text = copy(text)\n",
    "        cur_llh = best_llh = self.loglikelihood(text) \n",
    "        for iteration in tqdm(range(n_iter)):\n",
    "            new_text = self.__mutate(copy(text))\n",
    "            new_llh = self.loglikelihood(new_text)\n",
    "            if self.__accept(cur_llh, new_llh):\n",
    "                text = new_text\n",
    "                cur_llh = new_llh\n",
    "                if cur_llh > best_llh:\n",
    "                    best_llh = cur_llh\n",
    "                    best_decoded_text = copy(text)\n",
    "                    \n",
    "            if is_verbose and iteration % self.verbose == 0:\n",
    "                print(''.join(best_decoded_text))\n",
    "                print('--------------------------------------------------------------------------------')\n",
    "                \n",
    "        return ''.join(best_decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_decoder = MCMCDecoder(2, 'ru')\n",
    "mcmc_decoder.train(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 105/20000 [00:00<00:58, 342.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "йы гштуиргчавбайъыъгв лыъмраугъаь ёы ашеэыеёмъшш ъаиеос оашеаыепёрл вайеы н ьъалева сепемргчарагей эрара ьъзмеараймелчзараугзсръаьытэръауъжраеаъжъавш э асшрэай ьп ышезалытёеаралыразжрсеагрэеыалесрвраё эефевравбагаьюрв ваъжъашрс эьеауаюрпшрашъаёбмрагрэеыба сепемргчайъыубоаг ылаь ауъфъыеавбауемзмргчауамъгтараыепэ уеыруемразафрлемасшрюсрарау  ёжъавбашъьтыш айы уъмрауыъвзазаыеггсепемаьюрвта ё аугъвафл айы рп им ашеайеы н ьъарашеайеы въараг  ёжрмаъвтасглелрафл акл арашепбуеългзайырсмдфъшръваеа ша луълрмафл ашъаюъмеълаё мчиъашрсесрнайырсмдфъшроаьюрваыеггсепемафл ауалтаврштлтас эьеазапемъпауаытёстаеа шайы сыемгза ёыелш асайм лтаратурьъмафл айм леаё мчиъашъла шафтлчашъатвъыаг аглыенеалесараыъирмафл аъвталъйъычасыбисеафъваёбаьъм ашрас шфрм гчай л втафл аъгмраъэ ашъагйегтлалеса шатл шълаеаъгмрасл ашрётьчаъэ агйегълалеса луъпълаь в оафл ёбай мтфрлчапеашъэ ашеэыеьтаеалеваврггат лг шашеуъыш айы ьеглаъэ ашеадэафл аюа шаёбмайыеуа шай флраугъэьеаёбуемайыеуаэ м уеаташъэ аыеё лемеапь ы у ааьмзашъэыеас шъфш \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 5155/20000 [00:13<00:37, 397.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "проснувшись мы пересмотрели все добро награбленное шайкой на разбитом пароходе там оказались и сапоги и одеяла и платья и всякие другие вещи а еще много книг подзорная труба и три ящика сигар такими богачами мы с джимом еще никогда в жизни не были сигары оказались первый сорт до вечера мы валялись в лесу и разговаривали я читал книжки и вообще мы недурно провели время я рассказал джиму обо всем что произошло на пароходе и на пароме и сообщил ему кстати что это и называется приключением а он ответил что не желает больше никаких приключений джим рассказал что в ту минуту когда я залез в рубку а он прокрался обратно к плоту и увидел что плота больше нет он чуть не умер со страха так и решил что ему теперь крышка чем бы дело ни кончилось потому что если его не спасут так он утонет а если кто нибудь его спасет так отвезет домой чтобы получить за него награду а там мисс уотсон наверно продаст его на юг что ж он был прав он почти всегда бывал прав голова у него работала здорово  для негра конечно\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10083/20000 [00:26<00:23, 417.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "проснувшись мы пересмотрели все добро награбленное шайкой на разбитом пароходе там оказались и сапоги и одеяла и платья и всякие другие вещи а еще много книг подзорная труба и три ящика сигар такими богачами мы с джимом еще никогда в жизни не были сигары оказались первый сорт до вечера мы валялись в лесу и разговаривали я читал книжки и вообще мы недурно провели время я рассказал джиму обо всем что произошло на пароходе и на пароме и сообщил ему кстати что это и называется приключением а он ответил что не желает больше никаких приключений джим рассказал что в ту минуту когда я залез в рубку а он прокрался обратно к плоту и увидел что плота больше нет он чуть не умер со страха так и решил что ему теперь крышка чем бы дело ни кончилось потому что если его не спасут так он утонет а если кто нибудь его спасет так отвезет домой чтобы получить за него награду а там мисс уотсон наверно продаст его на юг что ж он был прав он почти всегда бывал прав голова у него работала здорово  для негра конечно\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15048/20000 [00:39<00:13, 359.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "проснувшись мы пересмотрели все добро награбленное шайкой на разбитом пароходе там оказались и сапоги и одеяла и платья и всякие другие вещи а еще много книг подзорная труба и три ящика сигар такими богачами мы с джимом еще никогда в жизни не были сигары оказались первый сорт до вечера мы валялись в лесу и разговаривали я читал книжки и вообще мы недурно провели время я рассказал джиму обо всем что произошло на пароходе и на пароме и сообщил ему кстати что это и называется приключением а он ответил что не желает больше никаких приключений джим рассказал что в ту минуту когда я залез в рубку а он прокрался обратно к плоту и увидел что плота больше нет он чуть не умер со страха так и решил что ему теперь крышка чем бы дело ни кончилось потому что если его не спасут так он утонет а если кто нибудь его спасет так отвезет домой чтобы получить за него награду а там мисс уотсон наверно продаст его на юг что ж он был прав он почти всегда бывал прав голова у него работала здорово  для негра конечно\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:53<00:00, 372.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCMC алгоритм на биграммах\n",
      "\n",
      "проснувшись мы пересмотрели все добро награбленное шайкой на разбитом пароходе там оказались и сапоги и одеяла и платья и всякие другие вещи а еще много книг подзорная труба и три ящика сигар такими богачами мы с джимом еще никогда в жизни не были сигары оказались первый сорт до вечера мы валялись в лесу и разговаривали я читал книжки и вообще мы недурно провели время я рассказал джиму обо всем что произошло на пароходе и на пароме и сообщил ему кстати что это и называется приключением а он ответил что не желает больше никаких приключений джим рассказал что в ту минуту когда я залез в рубку а он прокрался обратно к плоту и увидел что плота больше нет он чуть не умер со страха так и решил что ему теперь крышка чем бы дело ни кончилось потому что если его не спасут так он утонет а если кто нибудь его спасет так отвезет домой чтобы получить за него награду а там мисс уотсон наверно продаст его на юг что ж он был прав он почти всегда бывал прав голова у него работала здорово  для негра конечно\n",
      "\n",
      "\n",
      "Доля верно расшифрованных символовов 1.0\n"
     ]
    }
   ],
   "source": [
    "decoded_test_text_3 = mcmc_decoder.decode(encoded_test_text)\n",
    "print(\"MCMC алгоритм на биграммах\\n\")\n",
    "print(decoded_test_text_3)\n",
    "print(\"\\n\")\n",
    "print(f\"Доля верно расшифрованных символовов {accuracy(mcmc_decoder.preprocess(test_text), decoded_test_text_3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Расшифровка тестового текста <a name =\"decoding\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расшифруем еще одно закодированное сообщение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_message = \"დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведем в алфавит, на котором обучались"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_letters = ''.join(set(secret_message))\n",
    "rus_letters = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '[:len(encoded_letters)]\n",
    "secret_message_ru = secret_message.translate(str.maketrans(encoded_letters, rus_letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 204/60000 [00:00<01:10, 853.48it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "уъдйещрещйлйауесбхптдчсржейдйеобнайесбхптдчсржеаугъаезеёабцбеъббшфусйиегбабхржедуцгбеохбнйатачеъгбхууещъуцбещрещъуеълудтдйеохтщйдчсбейеобдзнйауептгъйптдчсржештддемтеобъдулсууенуащухабуемтлтсйуегзхътекбаиегбсунсбеиесйнуцбесуебшуфтв\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 5125/60000 [00:04<00:46, 1185.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "если бы бимите новзальный или дорти новзальный текст у этого соожчения котовый легко дворитать сковее бсего бы бсе смелали двабильно и долурите заксизальный жалл па дослемнее ретбевтое памание кувса хотя конерно я нирего не ожечаш\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 10312/60000 [00:10<00:53, 924.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "если вы вимите нордальный или почти нордальный текст у этого соожбения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный жалл за послемнее четвертое замание курса хотя конечно я ничего не ожебаю\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 15268/60000 [00:14<00:38, 1167.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "если вы вимите нордальный или почти нордальный текст у этого соожбения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный жалл за послемнее четвертое замание курса хотя конечно я ничего не ожебаю\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 20231/60000 [00:19<00:36, 1099.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаж\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 25322/60000 [00:24<00:29, 1181.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаж\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 30301/60000 [00:29<00:27, 1078.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаж\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 35182/60000 [00:34<00:20, 1189.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаж\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 40158/60000 [00:38<00:20, 965.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаж\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 45343/60000 [00:44<00:12, 1175.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаж\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 50355/60000 [00:48<00:08, 1183.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаж\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 55247/60000 [00:53<00:04, 1156.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаж\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:58<00:00, 1033.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаж\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "decoded_secret_message = mcmc_decoder.decode(secret_message_ru, n_iter=60000)\n",
    "print(decoded_secret_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Сравнение моделей  <a name=\"n_gramm_mcmc\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_quality(train_text, test_text, encoded_text_text, lang = 'ru'):\n",
    "    \n",
    "    for n_gram in range(1,10):\n",
    "        mcmc_decoder = MCMCDecoder(n_gram, lang)\n",
    "        mcmc_decoder.train(train_text)\n",
    "        decoded_test_text = mcmc_decoder.decode(encoded_text_text,  is_verbose = False)\n",
    "        acc = accuracy(mcmc_decoder.preprocess(test_text), decoded_test_text)\n",
    "        print(f\"Доля верно расшифрованных символовов {acc} для {n_gram}-грамм\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:36<00:00, 548.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верно расшифрованных символовов 0.3655378486055777 для 1-грамм\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:12<00:00, 275.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верно расшифрованных символовов 0.08366533864541832 для 2-грамм\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:39<00:00, 200.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верно расшифрованных символовов 1.0 для 3-грамм\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:48<00:00, 184.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верно расшифрованных символовов 0.06573705179282868 для 4-грамм\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:31<00:00, 219.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верно расшифрованных символовов 0.0796812749003984 для 5-грамм\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:29<00:00, 222.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верно расшифрованных символовов 0.0 для 6-грамм\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:48<00:00, 184.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верно расшифрованных символовов 0.12151394422310757 для 7-грамм\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:04<00:00, 161.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верно расшифрованных символовов 0.20916334661354583 для 8-грамм\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:45<00:00, 189.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верно расшифрованных символовов 0.0 для 9-грамм\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print_quality(train_text, test_text, encoded_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, если n > 3, то алгоритм уже не может давать хорошее качество. Логично предположить, что если увеличить обучающий корпус текстов, то можно повыить качество в том числе и на больших n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Применение модели  <a name=\"model_usage\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бонус: какие вы можете придумать применения для этой модели? Пляшущие человечки ведь не так часто встречаются в жизни (хотя встречаются! и это самое потрясающее во всей этой истории, но об этом я расскажу потом).\n",
    "\n",
    "Данную модель можно использовать например для восстановления исходного текста в ситуации когда сбивается кодировка, при условии, что каждому символу в неправильной кодировке соответствует один символ в правильной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
